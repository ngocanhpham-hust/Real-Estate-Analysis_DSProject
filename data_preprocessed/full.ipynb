{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b316e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ceace8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING ML IMPUTATION FOR MISSING VALUES ---\n",
      "  > Imputing: n_bedrooms\n",
      "  > Imputing: n_bathrooms\n",
      "  > Imputing: n_floors\n",
      "  > Imputing: front_width\n",
      "  > Imputing: front_road_width\n",
      "  > Imputing: interior\n",
      "--- CALCULATING COORDINATE AVERAGES BY REGION ---\n",
      "\n",
      "===========================================================================\n",
      "DATA FIELD           | ORIGINAL NaN | FINAL NaN  | RECOVERY RATE\n",
      "---------------------------------------------------------------------------\n",
      "Unnamed: 0           | 0            | 0          | 100%\n",
      "property_type        | 0            | 0          | 100%\n",
      "price                | 1367         | 0          | 100.0%\n",
      "area                 | 0            | 0          | 100%\n",
      "n_bedrooms           | 4218         | 0          | 100.0%\n",
      "n_bathrooms          | 5117         | 0          | 100.0%\n",
      "n_floors             | 8194         | 0          | 100.0%\n",
      "address              | 3            | 3          | 0.0%\n",
      "city_province        | 0            | 0          | 100%\n",
      "district             | 0            | 0          | 100%\n",
      "legal_docs           | 1875         | 1484       | 20.9%\n",
      "facing_direction     | 10697        | 9855       | 7.9%\n",
      "front_width          | 7729         | 0          | 100.0%\n",
      "balcony_direction    | 14172        | 13174      | 7.0%\n",
      "raw_price            | 0            | 0          | 100%\n",
      "raw_area             | 0            | 0          | 100%\n",
      "raw_n_bedrooms       | 4218         | 3598       | 14.7%\n",
      "raw_n_bathrooms      | 5117         | 4438       | 13.3%\n",
      "price_unit           | 6773         | 5406       | 20.2%\n",
      "front_width_unit     | 12421        | 11546      | 7.0%\n",
      "front_road_width     | 13154        | 0          | 100.0%\n",
      "front_road_width_unit | 13154        | 12195      | 7.3%\n",
      "latitude             | 5415         | 1675       | 69.1%\n",
      "longitude            | 5415         | 1675       | 69.1%\n",
      "title                | 5417         | 5409       | 0.1%\n",
      "description          | 5417         | 5409       | 0.1%\n",
      "interior             | 10672        | 0          | 100.0%\n",
      "raw_front_width      | 12421        | 11546      | 7.0%\n",
      "raw_front_road_width | 13154        | 12195      | 7.3%\n",
      "raw_n_floors         | 11546        | 10678      | 7.5%\n",
      "===========================================================================\n",
      "SUCCESS! Cleaned data saved to: full_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Utility to remove non-printable characters\n",
    "def clean_excel_string(val):\n",
    "    if isinstance(val, str):\n",
    "        # Removes ASCII control characters (0-31)\n",
    "        return re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f]', '', val)\n",
    "    return val\n",
    "\n",
    "# --- 1. IMPORT & PREPROCESS ---\n",
    "# Load dataset\n",
    "df = pd.read_csv('full.csv')\n",
    "df_raw_count = df.isna().sum() \n",
    "\n",
    "# Drop unnecessary columns (area_unit and scraper) and rows missing critical data\n",
    "cols_to_drop = ['area_unit', 'scraper']\n",
    "df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')\n",
    "df = df.dropna(subset=['price', 'property_type', 'area'])\n",
    "\n",
    "# Business Logic: Set floor count to 1 for Apartments/Condos if left empty\n",
    "apt_types = ['Căn hộ chung cư', 'Căn hộ chung cư mini', 'Condotel']\n",
    "if 'n_floors' in df.columns:\n",
    "    df.loc[(df['property_type'].isin(apt_types)) & (df['n_floors'].isna()), 'n_floors'] = 1\n",
    "\n",
    "# --- 2. MACHINE LEARNING IMPUTATION LOGIC ---\n",
    "def smart_imputer(df_input, target_col):\n",
    "    if target_col not in df_input.columns:\n",
    "        return df_input[target_col] if target_col in df_input.columns else None\n",
    "    \n",
    "    working_df = df_input.copy()\n",
    "    # Features used to learn the patterns\n",
    "    features = ['property_type', 'price', 'area', 'city_province', 'district']\n",
    "    features = [f for f in features if f in working_df.columns]\n",
    "    \n",
    "    # Encode categorical features for mathematical processing\n",
    "    for col in features:\n",
    "        if working_df[col].dtype == 'object':\n",
    "            working_df[col] = LabelEncoder().fit_transform(working_df[col].astype(str))\n",
    "\n",
    "    train_set = working_df[working_df[target_col].notna()]\n",
    "    predict_set = working_df[working_df[target_col].isna()]\n",
    "    \n",
    "    if len(predict_set) > 0 and len(train_set) > 0:\n",
    "        # CASE A: Numeric Data (Floors, Width, Bedrooms, etc.) -> Use Regressor\n",
    "        if df_input[target_col].dtype in [np.float64, np.int64]:\n",
    "            model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "            model.fit(train_set[features], train_set[target_col])\n",
    "            preds = model.predict(predict_set[features])\n",
    "            \n",
    "            if 'n_' in target_col: # Round results for count-based columns\n",
    "                preds = np.round(preds)\n",
    "            df_input.loc[df_input[target_col].isna(), target_col] = preds\n",
    "            \n",
    "        # CASE B: Text/Categorical Data (Interior) -> Use Classifier\n",
    "        else:\n",
    "            model = RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)\n",
    "            le_target = LabelEncoder()\n",
    "            y_train = le_target.fit_transform(train_set[target_col].astype(str))\n",
    "            \n",
    "            model.fit(train_set[features], y_train)\n",
    "            y_pred = model.predict(predict_set[features])\n",
    "            # Decode numbers back to original text (e.g., \"Full Furniture\", \"Basic\")\n",
    "            df_input.loc[df_input[target_col].isna(), target_col] = le_target.inverse_transform(y_pred)\n",
    "    \n",
    "    return df_input[target_col]\n",
    "\n",
    "# --- 3. EXECUTE ML PROCESSING ---\n",
    "print(\"--- STARTING ML IMPUTATION FOR MISSING VALUES ---\")\n",
    "targets = ['n_bedrooms', 'n_bathrooms', 'n_floors', 'front_width', 'front_road_width', 'interior']\n",
    "for target in targets:\n",
    "    if target in df.columns:\n",
    "        print(f\"  > Imputing: {target}\")\n",
    "        df[target] = smart_imputer(df, target)\n",
    "\n",
    "# --- 4. GEOSPATIAL COORDINATES PROCESSING (AVERAGING) ---\n",
    "print(\"--- CALCULATING COORDINATE AVERAGES BY REGION ---\")\n",
    "if 'latitude' in df.columns and 'longitude' in df.columns:\n",
    "    # Step 1: Fill NaN using the mean of the same District\n",
    "    df['latitude'] = df['latitude'].fillna(df.groupby(['city_province', 'district'])['latitude'].transform('mean'))\n",
    "    df['longitude'] = df['longitude'].fillna(df.groupby(['city_province', 'district'])['longitude'].transform('mean'))\n",
    "    \n",
    "    # Step 2: For districts with zero coordinate data, fallback to the Province average\n",
    "    df['latitude'] = df['latitude'].fillna(df.groupby('city_province')['latitude'].transform('mean'))\n",
    "    df['longitude'] = df['longitude'].fillna(df.groupby('city_province')['longitude'].transform('mean'))\n",
    "\n",
    "# --- 5. FINAL DATA FORMATTING ---\n",
    "# Convert count-based columns to Integer type\n",
    "for col in ['n_bedrooms', 'n_bathrooms', 'n_floors']:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).round().astype(int)\n",
    "\n",
    "# Apply character cleaning across the entire dataframe\n",
    "df = df.map(clean_excel_string)\n",
    "\n",
    "# --- 6. METRICS REPORT & EXPORT ---\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(f\"{'DATA FIELD':<20} | {'ORIGINAL NaN':<12} | {'FINAL NaN':<10} | {'RECOVERY RATE'}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "nan_after = df.isna().sum()\n",
    "for col in df_raw_count.index:\n",
    "    if col in df.columns:\n",
    "        before = df_raw_count[col]\n",
    "        after = nan_after[col]\n",
    "        recovered = before - after\n",
    "        pct = f\"{(recovered/before*100):.1f}%\" if before > 0 else \"100%\"\n",
    "        print(f\"{col:<20} | {before:<12} | {after:<10} | {pct}\")\n",
    "\n",
    "# --- 7. EXPORT TO CSV ---\n",
    "output_filename = 'full_cleaned.csv'\n",
    "# utf-8-sig ensures Vietnamese characters are readable in Excel CSV\n",
    "df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"=\"*75)\n",
    "print(f\"SUCCESS! Cleaned data saved to: {output_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
